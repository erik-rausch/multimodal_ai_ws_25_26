{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866606e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow\n",
    "!pip install python-dotenv\n",
    "!pip install snac peft soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8299375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from ask_lisa import ask_lisa\n",
    "from dotenv import load_dotenv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/training-1/asr_dataset_files/asr_bundestag\"\n",
    "train = base_dir + \"/train_nodev\"\n",
    "validate = base_dir + \"/train_dev\"\n",
    "test = base_dir + \"/test\"\n",
    "wav_dir = \"/training-1/asr/bundestag/dataset/wavs\"\n",
    "prompts = \"../../system_prompts/\"\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d9fe6-4c1a-4997-adb4-18f8cfafd4dd",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a164ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "\n",
    "with open(train + \"/wav.scp\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        words = line.strip().split()\n",
    "        mapping.update({words[0]: [words[1]]})\n",
    "\n",
    "for i, (key, value) in enumerate(mapping.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(key, \": \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc89b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train + \"/text\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        words = line.strip().split(maxsplit=1)\n",
    "        mapping[words[0]].append(words[1])\n",
    "\n",
    "for i, (key, value) in enumerate(mapping.items()):\n",
    "    if i >= 2:\n",
    "        break\n",
    "    print(key, \": \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3da28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = {}\n",
    "\n",
    "with open(train + \"/text\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        count = len(line.strip().split()) - 1\n",
    "        if count in word_count:\n",
    "            word_count[count] = word_count[count] + 1\n",
    "        else:\n",
    "            word_count[count] = 1\n",
    "\n",
    "counts = sorted(word_count.keys())\n",
    "frequencies = [word_count[c] for c in counts]\n",
    "\n",
    "plt.bar(counts, frequencies)\n",
    "plt.xlabel(\"Wörter pro Transkript\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mapping = {}\n",
    "for key, value in mapping.items():\n",
    "    count = len(value[1].split())\n",
    "    if 70 < count:\n",
    "        filtered_mapping.update({key: value})\n",
    "\n",
    "mapping = filtered_mapping\n",
    "\n",
    "for i, (key, value) in enumerate(mapping.items()):\n",
    "    if i >= 2:\n",
    "        break\n",
    "    print(key, \": \", value)\n",
    "\n",
    "print(len(mapping.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompts + \"check_context_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    system_prompt_check_context = f.read()\n",
    "    \n",
    "with open(prompts + \"generate_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    system_prompt = f.read()\n",
    "\n",
    "with open(prompts + \"verify_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    system_prompt_verify = f.read() + system_prompt\n",
    "\n",
    "def check_context(context):\n",
    "    res = ask_lisa(system_prompt_check_context, context)\n",
    "    print(res)\n",
    "    try:\n",
    "        return json.loads(res).get(\"context\") == \"ok\"\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Antwort war kein gültiges JSON:\", res)\n",
    "        return False\n",
    "\n",
    "def generate_qa(context):\n",
    "    qa_res = ask_lisa(system_prompt, context)\n",
    "\n",
    "    try:\n",
    "        qa_all = json.loads(qa_res)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Antwort war kein gültiges JSON:\", qa_res)\n",
    "        return None\n",
    "\n",
    "    verify = ask_lisa(\n",
    "        system_prompt_verify,\n",
    "        f\"\"\"\n",
    "        Kontext:\n",
    "        {context}\n",
    "        Antwort:\n",
    "        {qa_res}\n",
    "        \"\"\"\n",
    "    )\n",
    "    try:\n",
    "        verified = json.loads(verify)\n",
    "        print(verify)\n",
    "        if verified.get(\"quality\") == \"ok\":\n",
    "            return qa_all\n",
    "        else:\n",
    "            print(\"Fragen korrigiert!\")\n",
    "            return verified.get(\"data\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Antwort war kein gültiges JSON:\", qa_res)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d646a-59d8-4d6e-9e4a-deaea931520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ungeeigneter Kontext\n",
    "context = \"kein geschenk das ist verdient meine damen und herren durch dieses projekt ergeben sich man kann es kaum glauben großartige chancen merken sie sich das meine damen und herren kein anderes land kann so etwas vollbringen\"\n",
    "print(check_context(context))\n",
    "\n",
    "# Ungeeigneter Kontext\n",
    "context = \"aufwendig und eigentlich nicht das was wir haben wollten da müsste noch mal ordentlich power reingesteckt werden um diese sache voranzutreiben ein anderer punkt der natürlich auch schwierig ist den sie sich vorstellen können ist der support wie es neu deutsch heißt also die unterstützung denn sie müssen sich das so vorstellen es haben auf einen satz sehr viele gesundheitsämter jetzt den anschluss gemacht und es ist immer sehr schwer in so einer wachstumsphase die\"\n",
    "print(check_context(context))\n",
    "\n",
    "# Geeigneter Kontext\n",
    "context = \"es gibt zahlreiche nicht abklingende proteste es gibt initiativen es gibt self made projekte petitionen umfragen zeigen dass große teile der gesellschaft bereit sind jetzt wo wir hier reden haben wir vor dem bundestag eine begleitende kundgebung mit über zehn bewegungen und es gibt jetzt gerade redebeiträge und die zeigen ihnen auch wieder dass es nicht nur diese petition ist sondern dass es hunderttausende wenn nicht sogar millionen von menschen sind die tagtäglich immer wieder dafür kämpfen dass hier endlich was passiert im bereich der mobilitäts und verkehrswende zum schluss\"\n",
    "print(check_context(context))\n",
    "\n",
    "# Geeigneter Kontext\n",
    "context = \"vielen dank für die gelegenheit frau ministerin ich freue mich auch sehr über ihre aussagen bezüglich der gehsteigbelästigung das ist ein sehr wichtiges thema wir sind gerade im kontakt mit unseren genossinnen und genossen der linksfraktion in hessen da ist das problem dass die dortige schwarz grüne regierung gerne auf den bund zeigt der dann wiederum auf die länder zeigt wie können sie denn garantieren dass diese regelung die sie jetzt erarbeiten dann auch wirklich umgesetzt wird also ist da etwas in\"\n",
    "print(check_context(context))\n",
    "\n",
    "# Geeigneter Kontext\n",
    "context = \"alle mitgenommen und gezeigt wie wichtig die spracherziehung bereits in der kita ist es ist rundum evaluiert es ist von allen seiten als erfolgreich anerkannt deswegen ist jetzt der zeitpunkt dieses programm in die regelfinanzierung zu überführen das sieht auch das kita qualitätsgesetz vor eines der zentralen kriterien für die kitaqualität ist die sprachförderung deswegen setze ich mich dafür ein dass wir das gemeinsam hinkriegen vor allen dingen setze ich mich dafür ein dass wir mit den ländern auch zu einer guten übergangsregelung kommen sie wissen es\"\n",
    "print(check_context(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac27737",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_qa(\"es gibt zahlreiche nicht abklingende proteste es gibt initiativen es gibt self made projekte petitionen umfragen zeigen dass große teile der gesellschaft bereit sind jetzt wo wir hier reden haben wir vor dem bundestag eine begleitende kundgebung mit über zehn bewegungen und es gibt jetzt gerade redebeiträge und die zeigen ihnen auch wieder dass es nicht nur diese petition ist sondern dass es hunderttausende wenn nicht sogar millionen von menschen sind die tagtäglich immer wieder dafür kämpfen dass hier endlich was passiert im bereich der mobilitäts und verkehrswende zum schluss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2882d-d2a4-4038-ab5c-dd7ec42647de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zu verbessernde Fragen und Antworten\n",
    "context = \"es gibt zahlreiche nicht abklingende proteste es gibt initiativen es gibt self made projekte petitionen umfragen zeigen dass große teile der gesellschaft bereit sind jetzt wo wir hier reden haben wir vor dem bundestag eine begleitende kundgebung mit über zehn bewegungen und es gibt jetzt gerade redebeiträge und die zeigen ihnen auch wieder dass es nicht nur diese petition ist sondern dass es hunderttausende wenn nicht sogar millionen von menschen sind die tagtäglich immer wieder dafür kämpfen dass hier endlich was passiert im bereich der mobilitäts und verkehrswende zum schluss\"\n",
    "verify = ask_lisa(\n",
    "system_prompt_verify,\n",
    "f\"\"\"\n",
    "Kontext:\n",
    "{context}\n",
    "Antwort:\n",
    "{{\n",
    "    \"level_1\": {{ \"question\": \"Wer arbeitet?\", \"answer\": \"Bürger, Bewegungen\" }},\n",
    "    \"level_2\": {{ \"question\": \"Was sagen die Politiker?\", \"answer\": \"Große Bereitschaft zur Verkehrswende\" }},\n",
    "    \"level_3\": {{ \"question\": \"Warum sind die Proteste sinnvoll?\", \"answer\": \"Sie zeigen demokratische Partizipation\" }}\n",
    "}}\n",
    "\"\"\"\n",
    ")\n",
    "print(verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893eb19-aee3-46c9-a9bd-f63d88d0d2a3",
   "metadata": {},
   "source": [
    "# Anmerkung\n",
    "**Die folgenden Zellen sind nicht mehr aktuell. Sie waren ein Prototyp. Die Funktionalität wurde in die eigentliche Datensatzgenerierung übernommen. Also bitte nicht wundern, wenn es nicht mehr richtig funktioniert**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c59288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch\n",
    "from snac import SNAC\n",
    "from datetime import datetime\n",
    "\n",
    "from peft import PeftModel\n",
    "import soundfile as sf\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"SebastianBodza/Kartoffel_Orpheus-3B_german_synthetic-v0.1\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"SebastianBodza/Kartoffel_Orpheus-3B_german_synthetic-v0.1\",\n",
    ")\n",
    "\n",
    "snac_model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\")\n",
    "snac_model = snac_model.to(\"cuda\")\n",
    "\n",
    "chosen_voice = \"Julian\"\n",
    "\n",
    "def process_single_prompt(prompt, chosen_voice):\n",
    "    if chosen_voice == \"in_prompt\" or chosen_voice == \"\":\n",
    "        full_prompt = prompt\n",
    "    else:\n",
    "        full_prompt = f\"{chosen_voice}: {prompt}\"\n",
    "    start_token = torch.tensor([[128259]], dtype=torch.int64)\n",
    "    end_tokens = torch.tensor([[128009, 128260]], dtype=torch.int64)\n",
    "\n",
    "    input_ids = tokenizer(full_prompt, return_tensors=\"pt\").input_ids\n",
    "    modified_input_ids = torch.cat([start_token, input_ids, end_tokens], dim=1)\n",
    "\n",
    "    input_ids = modified_input_ids.to(\"cuda\")\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=4000,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.1,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=128258,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    token_to_find = 128257\n",
    "    token_to_remove = 128258\n",
    "\n",
    "    token_indices = (generated_ids == token_to_find).nonzero(as_tuple=True)\n",
    "\n",
    "    if len(token_indices[1]) > 0:\n",
    "        last_occurrence_idx = token_indices[1][-1].item()\n",
    "        cropped_tensor = generated_ids[:, last_occurrence_idx + 1 :]\n",
    "    else:\n",
    "        cropped_tensor = generated_ids\n",
    "\n",
    "    masked_row = cropped_tensor[0][cropped_tensor[0] != token_to_remove]\n",
    "    row_length = masked_row.size(0)\n",
    "    new_length = (row_length // 7) * 7\n",
    "    trimmed_row = masked_row[:new_length]\n",
    "    code_list = [t - 128266 for t in trimmed_row]\n",
    "\n",
    "    return code_list\n",
    "\n",
    "\n",
    "def redistribute_codes(code_list):\n",
    "    layer_1 = []\n",
    "    layer_2 = []\n",
    "    layer_3 = []\n",
    "    for i in range((len(code_list) + 1) // 7):\n",
    "        layer_1.append(code_list[7 * i])\n",
    "        layer_2.append(code_list[7 * i + 1] - 4096)\n",
    "        layer_3.append(code_list[7 * i + 2] - (2 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 3] - (3 * 4096))\n",
    "        layer_2.append(code_list[7 * i + 4] - (4 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 5] - (5 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 6] - (6 * 4096))\n",
    "\n",
    "    codes = [\n",
    "        torch.tensor(layer_1).unsqueeze(0),\n",
    "        torch.tensor(layer_2).unsqueeze(0),\n",
    "        torch.tensor(layer_3).unsqueeze(0),\n",
    "    ]\n",
    "    codes = [c.to(\"cuda\") for c in codes]\n",
    "\n",
    "    audio_hat = snac_model.decode(codes)\n",
    "    return audio_hat\n",
    "\n",
    "def to_speech(text):\n",
    "    with torch.no_grad():\n",
    "        code_list = process_single_prompt(text, chosen_voice)\n",
    "        samples = redistribute_codes(code_list)\n",
    "\n",
    "    audio_numpy = samples.detach().squeeze().to(\"cpu\").numpy()\n",
    "    \n",
    "    # Audio in BytesIO Buffer schreiben statt in Datei\n",
    "    buffer = BytesIO()\n",
    "    sf.write(buffer, audio_numpy, 24000, format='WAV')\n",
    "    buffer.seek(0)  # Zurück zum Anfang des Buffers\n",
    "    \n",
    "    return buffer.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_speech(text):\n",
    "    tts.tts_to_file(text=text, file_path=\"output.wav\")\n",
    "    with open(\"output.wav\", \"rb\") as wav_file:\n",
    "        return wav_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0887b57ca4882bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163bd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(mapping.keys())\n",
    "\n",
    "context_audio = []\n",
    "context_text = []\n",
    "\n",
    "q_1_audio = []\n",
    "q_1_text = []\n",
    "a_1_text = []\n",
    "\n",
    "q_2_audio = []\n",
    "q_2_text = []\n",
    "a_2_text = []\n",
    "\n",
    "q_3_audio = []\n",
    "q_3_text = []\n",
    "a_3_text = []\n",
    "\n",
    "train_size = 2 #1200\n",
    "val_size = 1 #150\n",
    "test_size = 1 #150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88845d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(key):\n",
    "    context = mapping[key][1]\n",
    "    context_text.append(context)\n",
    "    with open(mapping[key][0], \"rb\") as wav_file:\n",
    "        context_audio.append(wav_file.read())\n",
    "    \n",
    "    level_1, level_2, level_3 = generate_qa(mapping[key][1])\n",
    "\n",
    "    q_1 = level_1.get(\"question\")\n",
    "    q_1_text.append(q_1)\n",
    "    q_1_audio.append(to_speech(q_1))\n",
    "    a_1_text.append(level_1.get(\"answer\"))\n",
    "\n",
    "    q_2 = level_2.get(\"question\")\n",
    "    q_2_text.append(q_2)\n",
    "    q_2_audio.append(to_speech(q_2))\n",
    "    a_2_text.append(level_2.get(\"answer\"))\n",
    "\n",
    "    q_3 = level_3.get(\"question\")\n",
    "    q_3_text.append(q_3)\n",
    "    q_3_audio.append(to_speech(q_3))\n",
    "    a_3_text.append(level_3.get(\"answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df():\n",
    "    return pd.DataFrame({\n",
    "    \"context_text\": context_text,\n",
    "    \"context_audio\": context_audio,\n",
    "    \"q_1_text\": q_1_text,\n",
    "    \"q_1_audio\": q_1_audio,\n",
    "    \"a_1_text\": a_1_text,\n",
    "    \"q_2_text\": q_2_text,\n",
    "    \"q_2_audio\": q_2_audio,\n",
    "    \"a_2_text\": a_2_text,\n",
    "    \"q_3_text\": q_3_text,\n",
    "    \"q_3_audio\": q_3_audio,\n",
    "    \"a_3_text\": a_3_text\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0084283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_arrays():\n",
    "    context_audio.clear()\n",
    "    context_text.clear()\n",
    "    q_1_audio.clear()\n",
    "    q_1_text.clear()\n",
    "    a_1_text.clear()\n",
    "    q_2_audio.clear()\n",
    "    q_2_text.clear()\n",
    "    a_2_text.clear()\n",
    "    q_3_audio.clear()\n",
    "    q_3_text.clear()\n",
    "    a_3_text.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdatensatz\n",
    "clear_arrays()\n",
    "\n",
    "for i in range(train_size):\n",
    "    key = random.choice(keys)\n",
    "    generate_sample(key)\n",
    "    keys.remove(key)\n",
    "\n",
    "train_df = to_df()\n",
    "train_df.to_parquet(\"train.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf547146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validierungsdatensatz\n",
    "clear_arrays()\n",
    "\n",
    "for i in range(val_size):\n",
    "    key = random.choice(keys)\n",
    "    generate_sample(key)\n",
    "    keys.remove(key)\n",
    "\n",
    "val_df = to_df()\n",
    "val_df.to_parquet(\"validate.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_arrays()\n",
    "\n",
    "# Testdatensatz\n",
    "for i in range(test_size):\n",
    "    key = random.choice(keys)\n",
    "    generate_sample(key)\n",
    "    keys.remove(key)\n",
    "\n",
    "test_df = to_df()\n",
    "test_df.to_parquet(\"test.parquet\", engine=\"pyarrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
