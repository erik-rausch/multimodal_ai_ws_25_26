{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec1e15-4c1d-46d4-9bd4-a92321e1c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snac peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a1afa-51c0-49af-b9d7-7e3689b883d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f06f281b8a4a258cd970cb8bd2e55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fdf43f112c4fad901548fba8f8c063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6845e57416a4fdf8089490f00d248f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07d6c60305b4e3c9147ca201f0f6162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1429fe37a94d81b465aa28c8bafc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d436751d38549ef82c331e5d69cbc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/5.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784ac89739c64d9db42ad7b7cf51cd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/22.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fe054b46d14779b1e6f66fa77e1ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prompt 1/1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio.transforms as T\n",
    "import os\n",
    "import torch\n",
    "from snac import SNAC\n",
    "\n",
    "from peft import PeftModel\n",
    "import soundfile as sf\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"SebastianBodza/Kartoffel_Orpheus-3B_german_synthetic-v0.1\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"SebastianBodza/Kartoffel_Orpheus-3B_german_synthetic-v0.1\",\n",
    ")\n",
    "\n",
    "snac_model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\")\n",
    "snac_model = snac_model.to(\"cuda\")\n",
    "\n",
    "chosen_voice = \"Julian\"\n",
    "\n",
    "prompts = [\n",
    "    'Tief im verwunschenen Wald, wo die Bäume uralte Geheimnisse flüsterten, lebte ein kleiner Gnom namens Fips, der die Sprache der Tiere verstand.',\n",
    "]\n",
    "\n",
    "def process_single_prompt(prompt, chosen_voice):\n",
    "    if chosen_voice == \"in_prompt\" or chosen_voice == \"\":\n",
    "        full_prompt = prompt\n",
    "    else:\n",
    "        full_prompt = f\"{chosen_voice}: {prompt}\"\n",
    "    start_token = torch.tensor([[128259]], dtype=torch.int64)\n",
    "    end_tokens = torch.tensor([[128009, 128260]], dtype=torch.int64)\n",
    "\n",
    "    input_ids = tokenizer(full_prompt, return_tensors=\"pt\").input_ids\n",
    "    modified_input_ids = torch.cat([start_token, input_ids, end_tokens], dim=1)\n",
    "\n",
    "    input_ids = modified_input_ids.to(\"cuda\")\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=4000,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.1,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=128258,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    token_to_find = 128257\n",
    "    token_to_remove = 128258\n",
    "\n",
    "    token_indices = (generated_ids == token_to_find).nonzero(as_tuple=True)\n",
    "\n",
    "    if len(token_indices[1]) > 0:\n",
    "        last_occurrence_idx = token_indices[1][-1].item()\n",
    "        cropped_tensor = generated_ids[:, last_occurrence_idx + 1 :]\n",
    "    else:\n",
    "        cropped_tensor = generated_ids\n",
    "\n",
    "    masked_row = cropped_tensor[0][cropped_tensor[0] != token_to_remove]\n",
    "    row_length = masked_row.size(0)\n",
    "    new_length = (row_length // 7) * 7\n",
    "    trimmed_row = masked_row[:new_length]\n",
    "    code_list = [t - 128266 for t in trimmed_row]\n",
    "\n",
    "    return code_list\n",
    "\n",
    "\n",
    "def redistribute_codes(code_list):\n",
    "    layer_1 = []\n",
    "    layer_2 = []\n",
    "    layer_3 = []\n",
    "    for i in range((len(code_list) + 1) // 7):\n",
    "        layer_1.append(code_list[7 * i])\n",
    "        layer_2.append(code_list[7 * i + 1] - 4096)\n",
    "        layer_3.append(code_list[7 * i + 2] - (2 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 3] - (3 * 4096))\n",
    "        layer_2.append(code_list[7 * i + 4] - (4 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 5] - (5 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 6] - (6 * 4096))\n",
    "\n",
    "    codes = [\n",
    "        torch.tensor(layer_1).unsqueeze(0),\n",
    "        torch.tensor(layer_2).unsqueeze(0),\n",
    "        torch.tensor(layer_3).unsqueeze(0),\n",
    "    ]\n",
    "    codes = [c.to(\"cuda\") for c in codes]\n",
    "\n",
    "    audio_hat = snac_model.decode(codes)\n",
    "    return audio_hat\n",
    "\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f\"Processing prompt {i + 1}/{len(prompts)}\")\n",
    "    with torch.no_grad():\n",
    "        code_list = process_single_prompt(prompt, chosen_voice)\n",
    "        samples = redistribute_codes(code_list)\n",
    "\n",
    "    audio_numpy = samples.detach().squeeze().to(\"cpu\").numpy()\n",
    "    sf.write(f\"output_{i}.wav\", audio_numpy, 24000)\n",
    "    print(f\"Saved output_{i}.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa0dfc-afe6-4ca4-aaf8-ea5bafa97c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
