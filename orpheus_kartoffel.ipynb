{
 "cells": [
  {
   "cell_type": "code",
   "id": "b9ec1e15-4c1d-46d4-9bd4-a92321e1c96e",
   "metadata": {},
   "source": [
    "!pip install snac peft soundfile"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c91a1afa-51c0-49af-b9d7-7e3689b883d5",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torchaudio.transforms as T\n",
    "import os\n",
    "import torch\n",
    "from snac import SNAC\n",
    "from datetime import datetime\n",
    "\n",
    "from peft import PeftModel\n",
    "import soundfile as sf\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"SebastianBodza/Kartoffel_Orpheus-3B_german_synthetic-v0.1\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"SebastianBodza/Kartoffel_Orpheus-3B_german_synthetic-v0.1\",\n",
    ")\n",
    "\n",
    "snac_model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\")\n",
    "snac_model = snac_model.to(\"cuda\")\n",
    "\n",
    "chosen_voice = \"Julian\"\n",
    "\n",
    "prompts = [\n",
    "    \"Was wird gefordert?\",\n",
    "    \"Welche Formen des Protests gibt es?\",\n",
    "    \"Warum ist die breite Beteiligung an der Mobilitätswende entscheidend?\",\n",
    "    \"Wie steht die Bundesrepublik im Einsatz digitaler Lernsoftware zur Überwindung von Lernrückständen?\",\n",
    "    \"Wofür soll digitale Technik eingesetzt werden?\",\n",
    "    \"Welche Technik wird erwähnt?\"\n",
    "]\n",
    "\n",
    "def process_single_prompt(prompt, chosen_voice):\n",
    "    if chosen_voice == \"in_prompt\" or chosen_voice == \"\":\n",
    "        full_prompt = prompt\n",
    "    else:\n",
    "        full_prompt = f\"{chosen_voice}: {prompt}\"\n",
    "    start_token = torch.tensor([[128259]], dtype=torch.int64)\n",
    "    end_tokens = torch.tensor([[128009, 128260]], dtype=torch.int64)\n",
    "\n",
    "    input_ids = tokenizer(full_prompt, return_tensors=\"pt\").input_ids\n",
    "    modified_input_ids = torch.cat([start_token, input_ids, end_tokens], dim=1)\n",
    "\n",
    "    input_ids = modified_input_ids.to(\"cuda\")\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=4000,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.1,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=128258,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    token_to_find = 128257\n",
    "    token_to_remove = 128258\n",
    "\n",
    "    token_indices = (generated_ids == token_to_find).nonzero(as_tuple=True)\n",
    "\n",
    "    if len(token_indices[1]) > 0:\n",
    "        last_occurrence_idx = token_indices[1][-1].item()\n",
    "        cropped_tensor = generated_ids[:, last_occurrence_idx + 1 :]\n",
    "    else:\n",
    "        cropped_tensor = generated_ids\n",
    "\n",
    "    masked_row = cropped_tensor[0][cropped_tensor[0] != token_to_remove]\n",
    "    row_length = masked_row.size(0)\n",
    "    new_length = (row_length // 7) * 7\n",
    "    trimmed_row = masked_row[:new_length]\n",
    "    code_list = [t - 128266 for t in trimmed_row]\n",
    "\n",
    "    return code_list\n",
    "\n",
    "\n",
    "def redistribute_codes(code_list):\n",
    "    layer_1 = []\n",
    "    layer_2 = []\n",
    "    layer_3 = []\n",
    "    for i in range((len(code_list) + 1) // 7):\n",
    "        layer_1.append(code_list[7 * i])\n",
    "        layer_2.append(code_list[7 * i + 1] - 4096)\n",
    "        layer_3.append(code_list[7 * i + 2] - (2 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 3] - (3 * 4096))\n",
    "        layer_2.append(code_list[7 * i + 4] - (4 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 5] - (5 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 6] - (6 * 4096))\n",
    "\n",
    "    codes = [\n",
    "        torch.tensor(layer_1).unsqueeze(0),\n",
    "        torch.tensor(layer_2).unsqueeze(0),\n",
    "        torch.tensor(layer_3).unsqueeze(0),\n",
    "    ]\n",
    "    codes = [c.to(\"cuda\") for c in codes]\n",
    "\n",
    "    audio_hat = snac_model.decode(codes)\n",
    "    return audio_hat\n",
    "\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f\"Processing prompt {i + 1}/{len(prompts)}\")\n",
    "    with torch.no_grad():\n",
    "        code_list = process_single_prompt(prompt, chosen_voice)\n",
    "        samples = redistribute_codes(code_list)\n",
    "\n",
    "    audio_numpy = samples.detach().squeeze().to(\"cpu\").numpy()\n",
    "    sf.write(f\"output_{i}.wav\", audio_numpy, 24000)\n",
    "    print(f\"Saved output_{i}.wav at {datetime.now()}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f929125-a22b-45df-a96b-608a157f73fa",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
