{
 "cells": [
  {
   "cell_type": "code",
   "id": "866606e1",
   "metadata": {
    "trusted": true
   },
   "source": "!pip install pyarrow\n!pip install python-dotenv\n!pip install snac peft soundfile",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d8299375",
   "metadata": {
    "trusted": true
   },
   "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nfrom ask_lisa import ask_lisa\nfrom dotenv import load_dotenv\nimport json",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c001ced1",
   "metadata": {
    "trusted": true
   },
   "source": "base_dir = \"/training-1/asr_dataset_files/asr_bundestag\"\ntrain = base_dir + \"/train_nodev\"\nvalidate = base_dir + \"/train_dev\"\ntest = base_dir + \"/test\"\nwav_dir = \"/training-1/asr/bundestag/dataset/wavs\"\n\nload_dotenv()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a164ea5",
   "metadata": {
    "trusted": true
   },
   "source": "mapping = {}\n\nwith open(train + \"/wav.scp\", \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        words = line.strip().split()\n        mapping.update({words[0]: [words[1]]})\n\nfor i, (key, value) in enumerate(mapping.items()):\n    if i >= 5:\n        break\n    print(key, \": \", value)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bbc89b26",
   "metadata": {
    "trusted": true
   },
   "source": "with open(train + \"/text\", \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        words = line.strip().split(maxsplit=1)\n        mapping[words[0]].append(words[1])\n\nfor i, (key, value) in enumerate(mapping.items()):\n    if i >= 2:\n        break\n    print(key, \": \", value)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f3da28f",
   "metadata": {
    "trusted": true
   },
   "source": "word_count = {}\n\nwith open(train + \"/text\", \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        count = len(line.strip().split()) - 1\n        if count in word_count:\n            word_count[count] = word_count[count] + 1\n        else:\n            word_count[count] = 1\n\ncounts = sorted(word_count.keys())\nfrequencies = [word_count[c] for c in counts]\n\nplt.bar(counts, frequencies)\nplt.xlabel(\"Wörter pro Transkript\")\nplt.ylabel(\"Häufigkeit\")\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3966ed9a",
   "metadata": {
    "trusted": true
   },
   "source": "filtered_mapping = {}\nfor key, value in mapping.items():\n    count = len(value[1].split())\n    if 70 < count:\n        filtered_mapping.update({key: value})\n\nmapping = filtered_mapping\n\nfor i, (key, value) in enumerate(mapping.items()):\n    if i >= 2:\n        break\n    print(key, \": \", value)\n\nprint(len(mapping.items()))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b5db0abf",
   "metadata": {
    "trusted": true
   },
   "source": "with open(\"system_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n    system_prompt = f.read()\n\ndef generate_qa(context):\n    qa_res = ask_lisa(system_prompt, context)\n\n    try:\n        qa_all = json.loads(qa_res)\n    except json.JSONDecodeError:\n        print(\"Antwort war kein gültiges JSON:\", qa_res)\n        return None, None, difficulty\n\n    return qa_all.get(\"level_1\", {}), qa_all.get(\"level_2\", {}), qa_all.get(\"level_3\", {})",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0ac27737",
   "metadata": {
    "trusted": true
   },
   "source": "generate_qa(\"es gibt zahlreiche nicht abklingende proteste es gibt initiativen es gibt self made projekte petitionen umfragen zeigen dass große teile der gesellschaft bereit sind jetzt wo wir hier reden haben wir vor dem bundestag eine begleitende kundgebung mit über zehn bewegungen und es gibt jetzt gerade redebeiträge und die zeigen ihnen auch wieder dass es nicht nur diese petition ist sondern dass es hunderttausende wenn nicht sogar millionen von menschen sind die tagtäglich immer wieder dafür kämpfen dass hier endlich was passiert im bereich der mobilitäts und verkehrswende zum schluss\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c2c59288",
   "metadata": {
    "trusted": true
   },
   "source": [
    "import torch\n",
    "import os\n",
    "import torch\n",
    "from snac import SNAC\n",
    "from datetime import datetime\n",
    "\n",
    "from peft import PeftModel\n",
    "import soundfile as sf\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"SebastianBodza/Kartoffel_Orpheus-3B_german_synthetic-v0.1\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"SebastianBodza/Kartoffel_Orpheus-3B_german_synthetic-v0.1\",\n",
    ")\n",
    "\n",
    "snac_model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\")\n",
    "snac_model = snac_model.to(\"cuda\")\n",
    "\n",
    "chosen_voice = \"Julian\"\n",
    "\n",
    "def process_single_prompt(prompt, chosen_voice):\n",
    "    if chosen_voice == \"in_prompt\" or chosen_voice == \"\":\n",
    "        full_prompt = prompt\n",
    "    else:\n",
    "        full_prompt = f\"{chosen_voice}: {prompt}\"\n",
    "    start_token = torch.tensor([[128259]], dtype=torch.int64)\n",
    "    end_tokens = torch.tensor([[128009, 128260]], dtype=torch.int64)\n",
    "\n",
    "    input_ids = tokenizer(full_prompt, return_tensors=\"pt\").input_ids\n",
    "    modified_input_ids = torch.cat([start_token, input_ids, end_tokens], dim=1)\n",
    "\n",
    "    input_ids = modified_input_ids.to(\"cuda\")\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=4000,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.1,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=128258,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    token_to_find = 128257\n",
    "    token_to_remove = 128258\n",
    "\n",
    "    token_indices = (generated_ids == token_to_find).nonzero(as_tuple=True)\n",
    "\n",
    "    if len(token_indices[1]) > 0:\n",
    "        last_occurrence_idx = token_indices[1][-1].item()\n",
    "        cropped_tensor = generated_ids[:, last_occurrence_idx + 1 :]\n",
    "    else:\n",
    "        cropped_tensor = generated_ids\n",
    "\n",
    "    masked_row = cropped_tensor[0][cropped_tensor[0] != token_to_remove]\n",
    "    row_length = masked_row.size(0)\n",
    "    new_length = (row_length // 7) * 7\n",
    "    trimmed_row = masked_row[:new_length]\n",
    "    code_list = [t - 128266 for t in trimmed_row]\n",
    "\n",
    "    return code_list\n",
    "\n",
    "\n",
    "def redistribute_codes(code_list):\n",
    "    layer_1 = []\n",
    "    layer_2 = []\n",
    "    layer_3 = []\n",
    "    for i in range((len(code_list) + 1) // 7):\n",
    "        layer_1.append(code_list[7 * i])\n",
    "        layer_2.append(code_list[7 * i + 1] - 4096)\n",
    "        layer_3.append(code_list[7 * i + 2] - (2 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 3] - (3 * 4096))\n",
    "        layer_2.append(code_list[7 * i + 4] - (4 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 5] - (5 * 4096))\n",
    "        layer_3.append(code_list[7 * i + 6] - (6 * 4096))\n",
    "\n",
    "    codes = [\n",
    "        torch.tensor(layer_1).unsqueeze(0),\n",
    "        torch.tensor(layer_2).unsqueeze(0),\n",
    "        torch.tensor(layer_3).unsqueeze(0),\n",
    "    ]\n",
    "    codes = [c.to(\"cuda\") for c in codes]\n",
    "\n",
    "    audio_hat = snac_model.decode(codes)\n",
    "    return audio_hat\n",
    "\n",
    "def to_speech(text):\n",
    "    with torch.no_grad():\n",
    "        code_list = process_single_prompt(text, chosen_voice)\n",
    "        samples = redistribute_codes(code_list)\n",
    "\n",
    "    audio_numpy = samples.detach().squeeze().to(\"cpu\").numpy()\n",
    "    \n",
    "    # Audio in BytesIO Buffer schreiben statt in Datei\n",
    "    buffer = BytesIO()\n",
    "    sf.write(buffer, audio_numpy, 24000, format='WAV')\n",
    "    buffer.seek(0)  # Zurück zum Anfang des Buffers\n",
    "    \n",
    "    return buffer.read()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "996a06fb",
   "metadata": {
    "trusted": true
   },
   "source": "def to_speech(text):\n    tts.tts_to_file(text=text, file_path=\"output.wav\")\n    with open(\"output.wav\", \"rb\") as wav_file:\n        return wav_file.read()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b0887b57ca4882bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "163bd6dc",
   "metadata": {
    "trusted": true
   },
   "source": "keys = list(mapping.keys())\n\ncontext_audio = []\ncontext_text = []\n\nq_1_audio = []\nq_1_text = []\na_1_text = []\n\nq_2_audio = []\nq_2_text = []\na_2_text = []\n\nq_3_audio = []\nq_3_text = []\na_3_text = []\n\ntrain_size = 2 #1200\nval_size = 1 #150\ntest_size = 1 #150",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c88845d3",
   "metadata": {
    "trusted": true
   },
   "source": "def generate_sample(key):\n    context = mapping[key][1]\n    context_text.append(context)\n    with open(mapping[key][0], \"rb\") as wav_file:\n        context_audio.append(wav_file.read())\n    \n    level_1, level_2, level_3 = generate_qa(mapping[key][1])\n\n    q_1 = level_1.get(\"question\")\n    q_1_text.append(q_1)\n    q_1_audio.append(to_speech(q_1))\n    a_1_text.append(level_1.get(\"answer\"))\n\n    q_2 = level_2.get(\"question\")\n    q_2_text.append(q_2)\n    q_2_audio.append(to_speech(q_2))\n    a_2_text.append(level_2.get(\"answer\"))\n\n    q_3 = level_3.get(\"question\")\n    q_3_text.append(q_3)\n    q_3_audio.append(to_speech(q_3))\n    a_3_text.append(level_3.get(\"answer\"))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da11ca70",
   "metadata": {
    "trusted": true
   },
   "source": "def to_df():\n    return pd.DataFrame({\n    \"context_text\": context_text,\n    \"context_audio\": context_audio,\n    \"q_1_text\": q_1_text,\n    \"q_1_audio\": q_1_audio,\n    \"a_1_text\": a_1_text,\n    \"q_2_text\": q_2_text,\n    \"q_2_audio\": q_2_audio,\n    \"a_2_text\": a_2_text,\n    \"q_3_text\": q_3_text,\n    \"q_3_audio\": q_3_audio,\n    \"a_3_text\": a_3_text\n})",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e0084283",
   "metadata": {
    "trusted": true
   },
   "source": "def clear_arrays():\n    context_audio.clear()\n    context_text.clear()\n    q_1_audio.clear()\n    q_1_text.clear()\n    a_1_text.clear()\n    q_2_audio.clear()\n    q_2_text.clear()\n    a_2_text.clear()\n    q_3_audio.clear()\n    q_3_text.clear()\n    a_3_text.clear()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dab8b593",
   "metadata": {
    "trusted": true
   },
   "source": "# Trainingsdatensatz\nclear_arrays()\n\nfor i in range(train_size):\n    key = random.choice(keys)\n    generate_sample(key)\n    keys.remove(key)\n\ntrain_df = to_df()\ntrain_df.to_parquet(\"train.parquet\", engine=\"pyarrow\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cf547146",
   "metadata": {
    "trusted": true
   },
   "source": "# Validierungsdatensatz\nclear_arrays()\n\nfor i in range(val_size):\n    key = random.choice(keys)\n    generate_sample(key)\n    keys.remove(key)\n\nval_df = to_df()\nval_df.to_parquet(\"validate.parquet\", engine=\"pyarrow\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0d2d8096",
   "metadata": {
    "trusted": true
   },
   "source": "clear_arrays()\n\n# Testdatensatz\nfor i in range(test_size):\n    key = random.choice(keys)\n    generate_sample(key)\n    keys.remove(key)\n\ntest_df = to_df()\ntest_df.to_parquet(\"test.parquet\", engine=\"pyarrow\")",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
